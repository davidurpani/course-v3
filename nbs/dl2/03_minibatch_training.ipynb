{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "03_minibatch_training.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidurpani/course-v3/blob/master/nbs/dl2/03_minibatch_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f_eh99yI5WY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "67c81ca5-f875-4e01-901c-5ab7ee775621"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3e2QnEUJS2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a0ed823-82d2-4037-8115-eb920343c0d5"
      },
      "source": [
        "cd /gdrive/My Drive/course-v3/nbs/dl2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/course-v3/nbs/dl2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdYeldnzIQN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av_htCn3IQOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from exp.nb_02 import *\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Timz4OVLIQOD",
        "colab_type": "text"
      },
      "source": [
        "## Initial setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg3amEFMIQOD",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHHytQ--IQOE",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=1786)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKzywYXJIQOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYMzN1ICIQOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c34397ac-251e-4249-c007-8dfdf7186011"
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://deeplearning.net/data/mnist/mnist.pkl.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo-TWxhGIQOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81QoGPllKcnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6f1246e-64e0-4cf3-863e-0806a44931d9"
      },
      "source": [
        "print(n,m,c,nh)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 784 tensor(10) 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu0_QJOQIQOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SbjevqoIQOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLBM5ZFYIQOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etCQgK-tIQOT",
        "colab_type": "text"
      },
      "source": [
        "### Cross entropy loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0KsdfauIQOT",
        "colab_type": "text"
      },
      "source": [
        "First, we will need to compute the softmax of our activations. This is defined by:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
        "\n",
        "or more concisely:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$ \n",
        "\n",
        "In practice, we will need the log of the softmax when we calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTio9rP6IQOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH5cvoOjIQOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4xkvNKLIQOZ",
        "colab_type": "text"
      },
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "\n",
        "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaT1Kw31IQOZ",
        "colab_type": "text"
      },
      "source": [
        "This can be done using numpy-style [integer array indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#integer-array-indexing). Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9btRhhFKIQOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f854d2d7-64be-468b-dd44-867ae195dd68"
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dEThGUpYJkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fcb76ac-7b56-4af8-ac7f-a8974fe73d02"
      },
      "source": [
        "sm_pred.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owt-Uz7TYJoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ba8df502-c57b-435f-f523-b507e86c4580"
      },
      "source": [
        "sm_pred[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.3606, -2.2986, -2.4876, -2.5169, -2.3141, -2.2303, -2.1797, -2.3231,\n",
              "        -2.1714, -2.2072], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-doX6HmcYo1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5b11744a-9e9a-439f-8580-5336d83ded7b"
      },
      "source": [
        "sm_pred[1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.3128, -2.2683, -2.4156, -2.5228, -2.2799, -2.2588, -2.2700, -2.2691,\n",
              "        -2.2416, -2.2237], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzWUoRA8YpBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8a10d84f-dd0d-4746-c2f6-a676a5caff8b"
      },
      "source": [
        "sm_pred[2]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.2711, -2.3209, -2.4146, -2.4444, -2.2503, -2.3018, -2.1788, -2.3144,\n",
              "        -2.3104, -2.2465], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px1WuIZdIQOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5aae64bd-e015-4e86-ae56-b7c35b1e0fc7"
      },
      "source": [
        "sm_pred[[0,1,2], [5,0,4]]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.2303, -2.3128, -2.2503], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpoa2gvkIQOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66bb1e51-9a85-4c93-cc3d-8dc49e623feb"
      },
      "source": [
        "y_train.shape[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUMWNoBGIQOi",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2081)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHEliLhQIQOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1tWs16tIQOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nll(sm_pred, y_train)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCj7sGquIQOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a8a8d21-1524-4c1f-eb33-9fc83192d5c7"
      },
      "source": [
        "loss"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2940, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFRLbkKBIQOq",
        "colab_type": "text"
      },
      "source": [
        "Note that the formula \n",
        "\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$ \n",
        "\n",
        "gives a simplification when we compute the log softmax, which was previously defined as `(x.exp()/(x.exp().sum(-1,keepdim=True))).log()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tpuu2jrIQOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5aoVvzdIQOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88FQZ-eqIQOv",
        "colab_type": "text"
      },
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp). The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "\n",
        "where a is the maximum of the $x_{j}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Te2UwmsIQOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x):\n",
        "    m = x.max(-1)[0]\n",
        "    return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IX2wbt-IQOx",
        "colab_type": "text"
      },
      "source": [
        "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue_gHmDkIQOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(logsumexp(pred), pred.logsumexp(-1))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkfnJUq1IQO0",
        "colab_type": "text"
      },
      "source": [
        "So we can use it for our `log_softmax` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d79YvYGIQO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1kO6l5aIQO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb_CwXcvIQO4",
        "colab_type": "text"
      },
      "source": [
        "Then use PyTorch's implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiFoQmM_IQO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTuJoPmdIQO7",
        "colab_type": "text"
      },
      "source": [
        "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awFKlVXCIQO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.cross_entropy(pred, y_train), loss)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itBK0xxjIQO-",
        "colab_type": "text"
      },
      "source": [
        "## Basic training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crK2yPKKIQO-",
        "colab_type": "text"
      },
      "source": [
        "Basically the training loop repeats over the following steps:\n",
        "- get the output of the model on a batch of inputs\n",
        "- compare the output to the labels we have and compute a loss\n",
        "- calculate the gradients of the loss with respect to every parameter of the model\n",
        "- update said parameters with those gradients to make them a little bit better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOdgxdHqIQO_",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2542)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN26_AZBIQO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itVR_qe7IQPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_m6WTZYIQPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "705eb212-811d-4d0e-b954-c676a95564d6"
      },
      "source": [
        "bs=64                  # batch size\n",
        "\n",
        "xb = x_train[0:bs]     # a mini-batch from x\n",
        "preds = model(xb)      # predictions\n",
        "preds[0], preds.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0446,  0.0173, -0.1716, -0.2009,  0.0019,  0.0857,  0.1362, -0.0071,\n",
              "          0.1445,  0.1088], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FgiGXf3IQPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f510a054-d5bf-4278-aa01-bd6f5f112224"
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(preds, yb)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2920, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx24aZPlIQPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "beecbc74-bb25-450b-e67b-3842137c8ab9"
      },
      "source": [
        "accuracy(preds, yb)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0781)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY60zBthIQPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.5   # learning rate\n",
        "epochs = 1 # how many epochs to train for"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCko9KVsIQPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "#         set_trace()\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        loss = loss_func(model(xb), yb)\n",
        "\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            for l in model.layers:\n",
        "                if hasattr(l, 'weight'):\n",
        "                    l.weight -= l.weight.grad * lr\n",
        "                    l.bias   -= l.bias.grad   * lr\n",
        "                    l.weight.grad.zero_()\n",
        "                    l.bias  .grad.zero_()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7H7YYVWZ0PJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08667802-838d-4da4-f7c8-eedd989b3e93"
      },
      "source": [
        "(n-1)//bs, n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(781, 50000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59ck8thKZm8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc378fb6-7266-4155-9342-2f3cedb93d0e"
      },
      "source": [
        "range((n-1)//bs + 1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 782)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYJAUCrUIQPO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6798e3f8-54af-4869-aace-1906b60c1758"
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0924, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6a_vTEzIQPQ",
        "colab_type": "text"
      },
      "source": [
        "## Using parameters and optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko4yjG1qIQPQ",
        "colab_type": "text"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzzKFcvWIQPR",
        "colab_type": "text"
      },
      "source": [
        "Use `nn.Module.__setattr__` and move relu to functional:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnCemIf_IQPR",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2818)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEYEkAckIQPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        \n",
        "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kP-txkMIQPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgNKMpqBIQPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cfa79186-9f50-4cf2-c7e6-97db915eddfb"
      },
      "source": [
        "for name,l in model.named_children(): print(f\"{name}: {l}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMZG1PHrIQPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "bc5a9029-72a9-4175-b03c-f213bb0da0c6"
      },
      "source": [
        "model"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw5_Z6N_IQPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccbf2c54-7a7e-4584-c733-007e618a1c34"
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTtdz8LbIQPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs + 1):\n",
        "            start_i = i*bs\n",
        "            end_i = start_i+bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            loss = loss_func(model(xb), yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters(): p -= p.grad * lr\n",
        "                model.zero_grad()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoYI8biSIQPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f81ad33-111a-4f79-f774-21181622ef40"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1062, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yymVOVxoIQPh",
        "colab_type": "text"
      },
      "source": [
        "Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AifX0y1yIQPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModule():\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        self._modules = {}\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        \n",
        "    def __setattr__(self,k,v):\n",
        "        if not k.startswith(\"_\"): self._modules[k] = v\n",
        "        super().__setattr__(k,v)\n",
        "        \n",
        "    def __repr__(self): return f'{self._modules}'\n",
        "    \n",
        "    def parameters(self):\n",
        "        for l in self._modules.values():\n",
        "            for p in l.parameters(): yield p"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TEmvXCJIQPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c55cb825-92e3-4a91-dd4f-12511d0537af"
      },
      "source": [
        "mdl = DummyModule(m,nh,10)\n",
        "mdl"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gV0sk3CIQPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "58c7c586-c017-46f5-b3b9-a41e1b8904aa"
      },
      "source": [
        "[o.shape for o in mdl.parameters()]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([50, 784]),\n",
              " torch.Size([50]),\n",
              " torch.Size([10, 50]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTpStknxIQPp",
        "colab_type": "text"
      },
      "source": [
        "### Registering modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCFwHWLiIQPp",
        "colab_type": "text"
      },
      "source": [
        "We can use the original `layers` approach, but we have to register the modules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH4fuhFjIQPp",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=2997)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyEYj3buIQPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJOBOKsgIQPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54dWG2foIQPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(layers)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo64-BvJIQPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "67699e52-317b-44ac-feec-81dc5b6bdef0"
      },
      "source": [
        "model"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbfp6Ux9IQPz",
        "colab_type": "text"
      },
      "source": [
        "### nn.ModuleList"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-DuvJNxIQP0",
        "colab_type": "text"
      },
      "source": [
        "`nn.ModuleList` does this for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIJqbDzxIQP1",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3173)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBdbA7yQIQP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX2MxU0EIQP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SequentialModel(layers)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VIUmbBdIQP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "bfd075bd-6ecb-467c-a798-2dabf40b32ad"
      },
      "source": [
        "model"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeQePUcoIQP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a3c06b0-fa12-4f39-b6d4-7728cfa71022"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0339, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NiQcvZcIQP-",
        "colab_type": "text"
      },
      "source": [
        "### nn.Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zjjpc87IQP-",
        "colab_type": "text"
      },
      "source": [
        "`nn.Sequential` is a convenient class which does the same as the above:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lf8UNI8IQP-",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3199)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw5Iod9gIQP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg2TXuzXIQQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bae878e9-4e51-455c-f166-f3d645c993f3"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1649, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbVv5A_XIQQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Sequential??"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4Ve8b_LIQQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "37da89d5-70ce-4135-81ac-6b2f8c3287e8"
      },
      "source": [
        "model"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyctLYFkeISG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Sequential??"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL4YuLFsIQQI",
        "colab_type": "text"
      },
      "source": [
        "### optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w8mx_iYIQQJ",
        "colab_type": "text"
      },
      "source": [
        "Let's replace our previous manually coded optimization step:\n",
        "\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "\n",
        "and instead use just:\n",
        "\n",
        "```python\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h22I2NAIQQJ",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3278)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2evZWLKIQQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer():\n",
        "    def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
        "        \n",
        "    def step(self):\n",
        "        with torch.no_grad():\n",
        "            for p in self.params: p -= p.grad * self.lr\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for p in self.params: p.grad.data.zero_()"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px0F9OhkIQQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4YfeUvBIQQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CwoCvWqIQQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqB5hDKOIQQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d66f714f-2537-4324-a9c5-1a328e1688e3"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1187, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpfHpyouIQQS",
        "colab_type": "text"
      },
      "source": [
        "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum, which we'll look at later - except we'll be doing it in a more flexible way!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH4DGDoCIQQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import optim"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Qdk344IQQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim.SGD.step??"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnHykwLRIQQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgYoKlwAIQQW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1744efe1-3cc0-46ba-ecac-fe6b0067f64a"
      },
      "source": [
        "model,opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3128, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inn86pyNIQQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJMcMUW7IQQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ec808c0-9688-4c31-f0d0-3565ae61ce4e"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1729, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjmqXx_4IQQd",
        "colab_type": "text"
      },
      "source": [
        "Randomized tests can be very useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKHIFQ5-IQQe",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3442)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YaiDrujIQQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.7"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaTgdIl3IQQf",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqn20fJPIQQg",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pAI5lPVIQQg",
        "colab_type": "text"
      },
      "source": [
        "It's clunky to iterate through minibatches of x and y values separately:\n",
        "\n",
        "```python\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "```\n",
        "\n",
        "Instead, let's do these two steps together, by introducing a `Dataset` class:\n",
        "\n",
        "```python\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCDO9Uz1IQQh",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3578)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tieL-YDyIQQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class Dataset():\n",
        "    def __init__(self, x, y): self.x,self.y = x,y\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self, i): return self.x[i],self.y[i]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp5MFV7JIQQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
        "assert len(train_ds)==len(x_train)\n",
        "assert len(valid_ds)==len(x_valid)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNi-hQYTIQQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7a71c192-4128-4703-9b48-b6931d6dd83b"
      },
      "source": [
        "xb,yb = train_ds[0:5]\n",
        "assert xb.shape==(5,28*28)\n",
        "assert yb.shape==(5,)\n",
        "xb,yb"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1y_rRGtIQQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zmYMd0QIQQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TocijPUzIQQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df04abfe-7340-4f52-9990-23fd48f2c83d"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2427, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsWpVAjFIQQq",
        "colab_type": "text"
      },
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNYUrV-BIQQr",
        "colab_type": "text"
      },
      "source": [
        "Previously, our loop iterated over batches (xb, yb) like this:\n",
        "\n",
        "```python\n",
        "for i in range((n-1)//bs + 1):\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "    ...\n",
        "```\n",
        "\n",
        "Let's make our loop much cleaner, using a data loader:\n",
        "\n",
        "```python\n",
        "for xb,yb in train_dl:\n",
        "    ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYV6ZvYKIQQr",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3674)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cph9TPPNIQQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
        "    def __iter__(self):\n",
        "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtG2jzzdIQQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHF3wwGXIQQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "assert xb.shape==(bs,28*28)\n",
        "assert yb.shape==(bs,)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAd62wqhIQQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "cb1f0cc4-51eb-4980-a67b-0149ca9f666b"
      },
      "source": [
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVHdTMKyIQQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdKvohTcIQQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for xb,yb in train_dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huHW0_7UIQQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42YALS-uIQQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23dfdb6d-d443-423e-b503-5b0b61a75869"
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1182, grad_fn=<NllLossBackward>), tensor(0.9844))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfrEk5UZIQQ5",
        "colab_type": "text"
      },
      "source": [
        "### Random sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOLeR6BPIQQ5",
        "colab_type": "text"
      },
      "source": [
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5KybTGdIQQ6",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=3942)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmHgjz98IQQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampler():\n",
        "    def __init__(self, ds, bs, shuffle=False):\n",
        "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbVKavJaIQQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ds = Dataset(*train_ds[:10])"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCGxWG5KIQQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32db8a87-8eac-4096-e729-85edf47f1a10"
      },
      "source": [
        "s = Sampler(small_ds,3,False)\n",
        "[o for o in s]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoTPPe0uIQQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1edc453a-55b1-4eee-deaf-84149f91edce"
      },
      "source": [
        "s = Sampler(small_ds,3,True)\n",
        "[o for o in s]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([4, 8, 2]), tensor([3, 9, 1]), tensor([5, 0, 7]), tensor([6])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAgNlqeoIQRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(b):\n",
        "    xs,ys = zip(*b)\n",
        "    return torch.stack(xs),torch.stack(ys)\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, ds, sampler, collate_fn=collate):\n",
        "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFyMooNDIQRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
        "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7MsoXtsIQRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgnhks9rIQRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "ec6d971c-453e-46d2-ae60-ea4e1727616b"
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6qbYRmFIQRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "471790af-56fb-4f41-f32d-f93216d2a0e5"
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXv5y17ZIQRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7f0fc3bf-4e78-43b9-ec02-4081e067da76"
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX8DTD0GIQRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06341777-08cb-4ab3-8453-22cae8fd9d6a"
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3803, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hyKOoxAIQRO",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDNumlYaIQRO",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=4171)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh8JSqh6IQRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn1v3zJQIQRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Whcj2sIQRR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcf00866-f5ee-48e4-a981-8075833fe669"
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7392, grad_fn=<NllLossBackward>), tensor(0.7812))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIRCEne6IQRS",
        "colab_type": "text"
      },
      "source": [
        "PyTorch's defaults work fine for most things however:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds5Wtpk9IQRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H10LuuTiIQRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37adf661-8397-4f79-f9aa-c845fe5c2c09"
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2013, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQCbWvVjIQRV",
        "colab_type": "text"
      },
      "source": [
        "Note that PyTorch's `DataLoader`, if you pass `num_workers`, will use multiple threads to call your `Dataset`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax05YUN7IQRV",
        "colab_type": "text"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHRQTIGvIQRW",
        "colab_type": "text"
      },
      "source": [
        "You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.\n",
        "\n",
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOVhVbRMIQRW",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=4260)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwuXKqFgIQRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        # Handle batchnorm / dropout\n",
        "        model.train()\n",
        "#         print(model.training)\n",
        "        for xb,yb in train_dl:\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        model.eval()\n",
        "#         print(model.training)\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc = 0.,0.\n",
        "            for xb,yb in valid_dl:\n",
        "                pred = model(xb)\n",
        "                tot_loss += loss_func(pred, yb)\n",
        "                tot_acc  += accuracy (pred,yb)\n",
        "        nv = len(valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "    return tot_loss/nv, tot_acc/nv"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEjyXYdYIQRY",
        "colab_type": "text"
      },
      "source": [
        "*Question*: Are these validation results correct if batch size varies?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyAO2uS1IQRY",
        "colab_type": "text"
      },
      "source": [
        "`get_dls` returns dataloaders for the training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WbXftjkIQRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAc8L2mOIQRa",
        "colab_type": "text"
      },
      "source": [
        "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YcZzmPsIQRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "e0666333-f94d-46bd-de18-e3ebf5fcd563"
      },
      "source": [
        "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model,opt = get_model()\n",
        "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.1458) tensor(0.9583)\n",
            "1 tensor(0.1172) tensor(0.9644)\n",
            "2 tensor(0.1337) tensor(0.9607)\n",
            "3 tensor(0.1046) tensor(0.9687)\n",
            "4 tensor(0.1061) tensor(0.9688)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_zgYPsXIQRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.9"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggpRDcYlIQRe",
        "colab_type": "text"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qp4GqR-IQRe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "79eead62-e5e9-4462-be94-09debdb7839e"
      },
      "source": [
        "!python notebook2script.py 03_minibatch_training.ipynb"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"notebook2script.py\", line 3, in <module>\n",
            "    import json,fire,re\n",
            "ModuleNotFoundError: No module named 'fire'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHvheO0gIQRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 112,
      "outputs": []
    }
  ]
}